{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento e Avaliação de Modelos para Previsão de Risco de Enchente\n",
    "\n",
    "Este notebook tem como objetivo treinar e avaliar dois modelos de classificação (Logistic Regression e Random Forest) para prever o `nivel_risco` de enchente com base no `acumulado_chuva_1_h_mm` e `cod_estacao` dos dados processados do CEMADEN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuração Inicial e Carregamento de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import joblib\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Configurações de visualização\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados processados\n",
    "df = pd.read_csv('../data/cemaden_official_processed_hourly.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Análise Exploratória Breve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuição do target (nivel_risco)\n",
    "print(df['nivel_risco'].value_counts(normalize=True) * 100)\n",
    "sns.countplot(x='nivel_risco', data=df)\n",
    "plt.title('Distribuição da Variável Alvo (nivel_risco)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relação entre acumulado_chuva_1_h_mm e nivel_risco\n",
    "sns.boxplot(x='nivel_risco', y='acumulado_chuva_1_h_mm', data=df)\n",
    "plt.title('Acumulado de Chuva (1h) por Nível de Risco')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preparação dos Dados para Modelagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleção de Features (X) e Target (y)\n",
    "# Vamos incluir 'cod_estacao' como feature categórica\n",
    "X = df[['acumulado_chuva_1_h_mm', 'cod_estacao']]\n",
    "y = df['nivel_risco']\n",
    "\n",
    "# Definir o transformador para One-Hot Encoding da coluna 'cod_estacao'\n",
    "# remainder='passthrough' mantém as outras colunas (acumulado_chuva_1_h_mm)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False), ['cod_estacao'])\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Divisão em conjuntos de treino e teste (80/20 estratificado)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Formato de X_train: {X_train.shape}\")\n",
    "print(f\"Formato de X_test: {X_test.shape}\")\n",
    "print(f\"Formato de y_train: {y_train.shape}\")\n",
    "print(f\"Formato de y_test: {y_test.shape}\")\n",
    "\n",
    "print(\"\\nDistribuição do nivel_risco no conjunto de treino:\")\n",
    "print(y_train.value_counts(normalize=True) * 100)\n",
    "\n",
    "print(\"\\nDistribuição do nivel_risco no conjunto de teste:\")\n",
    "print(y_test.value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modelo 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar o pipeline para Logistic Regression com pré-processamento\n",
    "pipeline_log_reg = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(random_state=42, solver='liblinear', max_iter=1000))\n",
    "])\n",
    "\n",
    "# Treinar o modelo\n",
    "pipeline_log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predições no conjunto de teste\n",
    "y_pred_log_reg_test = pipeline_log_reg.predict(X_test)\n",
    "\n",
    "# Predições no conjunto de treino (para verificar overfitting)\n",
    "y_pred_log_reg_train = pipeline_log_reg.predict(X_train)\n",
    "\n",
    "# Avaliação no conjunto de Teste\n",
    "print(\"Logistic Regression - Avaliação no CONJUNTO DE TESTE\")\n",
    "print(\"Acurácia:\", accuracy_score(y_test, y_pred_log_reg_test))\n",
    "print(\"Matriz de Confusão:\")\n",
    "print(confusion_matrix(y_test, y_pred_log_reg_test))\n",
    "print(\"Relatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred_log_reg_test))\n",
    "\n",
    "# Avaliação no conjunto de Treino\n",
    "print(\"\\nLogistic Regression - Avaliação no CONJUNTO DE TREINO\")\n",
    "print(\"Acurácia:\", accuracy_score(y_train, y_pred_log_reg_train))\n",
    "print(\"Relatório de Classificação:\")\n",
    "print(classification_report(y_train, y_pred_log_reg_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modelo 2: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar o pipeline para Random Forest com pré-processamento\n",
    "pipeline_rf_clf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42, n_estimators=100))\n",
    "])\n",
    "\n",
    "# Treinar o modelo\n",
    "pipeline_rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predições no conjunto de teste\n",
    "y_pred_rf_clf_test = pipeline_rf_clf.predict(X_test)\n",
    "\n",
    "# Predições no conjunto de treino (para verificar overfitting)\n",
    "y_pred_rf_clf_train = pipeline_rf_clf.predict(X_train)\n",
    "\n",
    "# Avaliação no conjunto de Teste\n",
    "print(\"Random Forest - Avaliação no CONJUNTO DE TESTE\")\n",
    "print(\"Acurácia:\", accuracy_score(y_test, y_pred_rf_clf_test))\n",
    "print(\"Matriz de Confusão:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf_clf_test))\n",
    "print(\"Relatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred_rf_clf_test))\n",
    "\n",
    "# Avaliação no conjunto de Treino\n",
    "print(\"\\nRandom Forest - Avaliação no CONJUNTO DE TREINO\")\n",
    "print(\"Acurácia:\", accuracy_score(y_train, y_pred_rf_clf_train))\n",
    "print(\"Relatório de Classificação:\")\n",
    "print(classification_report(y_train, y_pred_rf_clf_train))\n",
    "\n",
    "# Importância das Features (apenas para Random Forest e após o fit do pipeline)\n",
    "try:\n",
    "    # Obter o transformador OneHotEncoder do pipeline\n",
    "    onehot_transformer = pipeline_rf_clf.named_steps['preprocessor'].named_transformers_['onehot']\n",
    "    onehot_features = onehot_transformer.get_feature_names_out(['cod_estacao'])\n",
    "    \n",
    "    # As features numéricas são passadas através do 'remainder'\n",
    "    numeric_features = [col for col in X_train.columns if col not in ['cod_estacao']]\n",
    "    \n",
    "    # Combinar nomes das features na ordem correta\n",
    "    all_feature_names = np.concatenate([onehot_features, numeric_features])\n",
    "    \n",
    "    importances = pipeline_rf_clf.named_steps['classifier'].feature_importances_\n",
    "    \n",
    "    if len(all_feature_names) == len(importances):\n",
    "        feature_importance_df = pd.DataFrame({'feature': all_feature_names, 'importance': importances})\n",
    "        feature_importance_df = feature_importance_df.sort_values(by='importance', ascending=False)\n",
    "        \n",
    "        print(\"\\nImportância das Features (Random Forest):\")\n",
    "        print(feature_importance_df.head(10)) # Mostrar top 10 features\n",
    "        \n",
    "        plt.figure(figsize=(12, max(6, len(feature_importance_df.head(10)) * 0.5)))\n",
    "        sns.barplot(x='importance', y='feature', data=feature_importance_df.head(10), palette='viridis')\n",
    "        plt.title('Top 10 Features Mais Importantes - Random Forest')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Erro: Número de nomes de features ({len(all_feature_names)}) não corresponde ao número de importâncias ({len(importances)}).\")\n",
    "        print(\"Nomes das features extraídos:\", all_feature_names)\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao calcular ou exibir importância das features: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparação dos Modelos e Conclusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coletar métricas para comparação (do conjunto de TESTE)\n",
    "metrics_log_reg_test = classification_report(y_test, y_pred_log_reg_test, output_dict=True)\n",
    "metrics_rf_clf_test = classification_report(y_test, y_pred_rf_clf_test, output_dict=True)\n",
    "\n",
    "# Coletar métricas do conjunto de TREINO para verificar overfitting\n",
    "metrics_log_reg_train = classification_report(y_train, y_pred_log_reg_train, output_dict=True)\n",
    "metrics_rf_clf_train = classification_report(y_train, y_pred_rf_clf_train, output_dict=True)\n",
    "\n",
    "comparison_data = {\n",
    "    'Modelo': ['Logistic Regression', 'Random Forest'],\n",
    "    'Acurácia (Teste)': [accuracy_score(y_test, y_pred_log_reg_test), accuracy_score(y_test, y_pred_rf_clf_test)],\n",
    "    'Acurácia (Treino)': [accuracy_score(y_train, y_pred_log_reg_train), accuracy_score(y_train, y_pred_rf_clf_train)],\n",
    "    'F1-Score (Teste, weighted)': [metrics_log_reg_test['weighted avg']['f1-score'], metrics_rf_clf_test['weighted avg']['f1-score']],\n",
    "    'F1-Score (Treino, weighted)': [metrics_log_reg_train['weighted avg']['f1-score'], metrics_rf_clf_train['weighted avg']['f1-score']],\n",
    "    'Recall (Teste, Nível 2)': [metrics_log_reg_test.get('2', {}).get('recall', 0.0), metrics_rf_clf_test.get('2', {}).get('recall', 0.0)],\n",
    "    'Precisão (Teste, Nível 2)': [metrics_log_reg_test.get('2', {}).get('precision', 0.0), metrics_rf_clf_test.get('2', {}).get('precision', 0.0)]\n",
    "}\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "print(\"Tabela Comparativa dos Modelos (Métricas de Teste e Treino):\")\n",
    "print(df_comparison.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão Preliminar\n",
    "\n",
    "Com base na tabela acima, podemos discutir:\n",
    "1. Qual modelo apresentou melhor desempenho geral no conjunto de teste?\n",
    "2. Qual se saiu melhor na identificação dos casos de risco mais elevado (Nível 2) no teste?\n",
    "3. Há sinais de overfitting (grande diferença entre métricas de treino e teste)?\n",
    "4. Qual o impacto da inclusão da feature `cod_estacao` (analisando a importância das features do Random Forest)?\n",
    "\n",
    "Esta análise ajudará a decidir qual modelo (e pipeline de pré-processamento) será salvo e utilizado no script `2_train_model.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando o Modelo Escolhido (Exemplo)\n",
    "\n",
    "Supondo que o Random Forest (com o pipeline) seja o escolhido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo: Salvando o pipeline completo do Random Forest\n",
    "# model_to_save = pipeline_rf_clf \n",
    "# model_dir = '../ml_model'\n",
    "# if not os.path.exists(model_dir):\n",
    "#     os.makedirs(model_dir)\n",
    "# model_filename = os.path.join(model_dir, 'cemaden_flood_risk_model_pipeline.joblib')\n",
    "# joblib.dump(model_to_save, model_filename)\n",
    "# print(f\"Modelo (pipeline) salvo em {model_filename}\")\n",
    "\n",
    "# Descomente e ajuste conforme o modelo escolhido após a análise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
